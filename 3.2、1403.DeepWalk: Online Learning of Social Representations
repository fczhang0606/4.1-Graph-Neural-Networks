https://arxiv.org/pdf/1403.6652.pdf

https://www.bilibili.com/video/BV1K5411H7EQ?p=3&vd_source=26c583b46dbb1b1b34ae4743b60cf76f
https://www.bilibili.com/video/BV1pW4y1z7pb/?spm_id_from=333.788&vd_source=26c583b46dbb1b1b34ae4743b60cf76f



################################################################################################################################
conda create -n GNN_DeepWalk
conda activate GNN_DeepWalk

conda install python=3.8

https://pytorch.org/get-started/previous-versions/
conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge
################################################################################################################################
conda install ipykernel
conda install platformdirs
pip3 install ipywidgets
pip3 install --upgrade jupyter_core jupyter_client
################################################################################################################################
(sudo python -m ipykernel install --name XXX)
################################################################################################################################



################################################################################################################################
1\Deep Walk in karateclub

import karateclub
from karateclub import DeepWalk
import networkx as nx
import sklearn
from sklearn.cluster import KMeans

G = nx.karate_club_graph()
G.nodes[1]
G.nodes[23]

model = DeepWalk()
model.fit(G)

G_embedding = model.get_embedding()
G_embedding.shape

num_coms = 2
clusters = KMeans(n_clusters=num_coms).fit_predict(G_embedding)
print(clusters)
################################################################################################################################
2\ZZ's Deep Walk

import torch
import torch.nn as nn
import random

adj_list = [
[1,2,3], 
[0,2,3], 
[0, 1, 3], 
[0, 1, 2], 
[5, 6], 
[4,6], 
[4, 5], 
[1, 3]]
size_vertex = len(adj_list)

w=3
d=2
y=200
t=6
lr=0.025
v=[0, 1, 2, 3, 4, 5, 6, 7]
################################################################################################################################
def RandomWalk(node, t) :
    walk = [node]
    
    for i in range(t-1) :
        node = adj_list[node][random.randint(0, len(adj_list[node]) - 1)]
        walk.append(node)

    return walk
################################################################################################################################
class Model(torch.nn.Module) :

    def __init__(self) :
        super(Model, self).__init__()
        self.phi1 = nn.Parameter(torch.rand((size_vertex, d), requires_grad=True))
        self.phi2 = nn.Parameter(torch.rand((d, size_vertex), requires_grad=True))

    def forward(self, hot) :
        hid = torch.matmul(hot, self.phi1)
        out = torch.matmul(hid, self.phi2)
        return out
################################################################################################################################
def skip_gram(wvi,  w) :

    for j in range(len(wvi)) :
    
        for k in range(max(0, j-w), min(j+w, len(wvi))) :
            
            #generate one hot vector
            one_hot          = torch.zeros(size_vertex)
            one_hot[wvi[j]]  = 1
            
            out              = model(one_hot)
            loss             = torch.log(torch.sum(torch.exp(out))) - out[wvi[k]]
            loss.backward()
            
            for param in model.parameters():
                param.data.sub_(lr*param.grad)
                param.grad.data.zero_()
################################################################################################################################
model = Model()
for i in range(y):
    random.shuffle(v)
    for vi in v:
        wvi=RandomWalk(vi,t)
        skip_gram(wvi, w)
print(model.phi)


################################################################################################################################
3\Wiki
https://www.bilibili.com/video/BV1et4y187Gd/?spm_id_from=333.788&vd_source=26c583b46dbb1b1b34ae4743b60cf76f

pip install networkx gensim pandas numpy tqdm scikit-learn matplotlib

import networkx as nx
import pandas as pd
import numpy as np
import random
from tqdm import tqdm
import matplotlib.pyplot as plt
%matplotlib inline
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False

https://densitydesign.github.io/strumentalia-seealsogy
distance = 4
https://en.wikipedia.org/wiki/Ayn_Rand
https://en.wikipedia.org/wiki/Arthur_Schopenhauer
.tsv

df = pd.read_csv("1.tsv", sep = "\t")
df.head()
df.shape

G = nx.from_pandas_edgelist(df, "source", "target", edge_attr=True, create_using=nx.Graph())
len(G)

# plt.figure(figsize=(15, 14))
# nx.draw(G)
# plt.show()

def get_randomwalk(node, path_length):
    random_walk = [node]
    for i in range(path_length-1):
        temp = list(G.geighbors(node))
        temp = list(set(temp) - set(random_walk))
        if len(temp) == 0:
            break
            
        random_node = random.choice(temp)
        random_walk.append(random_node)
        node = random_node
        
    return random_walk
    
all_nodes = list(G.nodes())
all_nodes

get_randomwalk('random forest', 5)

gamma = 10
walk_length = 5
random_walks = []
for n in tqdm(all_nodes):
    for i in range(gamma):
        random_walks.append(get_randomwalk(n, walk_length))
        
len(random_walks)
random_walks[1]

from gensim.models import Word2Vec

model = Word2Vec(vector_size=256,
                    window=4,
                    sg=1,
                    hs=0,
                    negative=10,
                    alpha=0.03,
                    min_alpha=0.0007,
                    seed=14
                    )
model.build_vocab(random_walks, progress_per=2)
model.train(random_walks, total_examples=model.corpus_count, epochs=50, report_delay=1)

model.wv.get_vector('Ayn Rand').shape
model.wv.get_vector('Ayn Rand')

model.wv.similar_by_word('Ayn Rand')
################################################################################################################################
x = model.wv.vectors

from sklearn.decomposition import PCA
pca = PCA(n_components=2)
embed_2d = pca.fit_transform(X)
embed_2d.shape

plt.figure(figsize=(14, 14))
plt.scatter(embed_2d[:, 0], embed_2d[:, 1])
plt.show()

term = 'Ayn Rand'
term_256d = model.wv[term].reshape(1, -1)
term_256d.shape
term_2d = pca.transform(term_256d)
term_2d

plt.figure(figsize=(14, 14))
plt.scatter(embed_2d[:,0], embed_2d[:,1])
plt.scatter(term_2d[:,0], term_2d[:,1], c='r', s=200)
plt.show()

pagerank = nx.pagerank(G)
node_importance = sorted(pagerank.items(), key=lambda x:x[1], reverse=True)
n = 30
terms_chosen = []
for each in node_importance[:n]:
    terms_chosen.append(each[0])
terms_chosen.extend(['Ayn Rand', 'Arthur_Schopenhauer'])
terms_chosen
terms2index = model.wv.key_to_index
# index2term = model.wv.index_to_key
# term_index = np.array(term2index.values())

plt.figure(figsiez=(14, 14))
plt.scatter(embed_2d[:,0], embed_2d[:,1])

for item in terms_chosen:
    idx = term2index[item]
    plt.scatter(embed_2d[idx, 0], embed_2d[idx, 1], c='r', s=50)
    plt.annotate(item, xy=(embed_2d[idx,0], embed_2d[idx,1], c='k', fontsize=12))

plt.show()
################################################################################################################################
from sklearn.manifold import TSNE
tsne = TSNE(n_components=2, n_iter=1000)
embed_2d = tsne.fit_transform(X)

plt.figure(figsize=(14, 14))
plt.scatter(embed_2d[:,0], embed_2d[:,1])
plt.show()

plt.figure(figsize=(14, 14))
plt.scatter(embed_2d[:,0], embed_2d[:,1])

for item in terms_chosen:
    idx = term2index[item]
    plt.scatter(embed_2d[idx, 0], embed_2d[idx, 1], c='r', s=50)
    plt.annotate(item, xy=(embed_2d[idx,0], embed_2d[idx,1], c='k', fontsize=12))

plt.show()

embed_2d.shape

terms_chosen_mask = np.zeros(X.shape[0])
for item in terms_chosen:
    idx = term2index[item]
    terms_chosen_mask[idx] = 1

df = pd.DataFrame()
df['X'] = embed_2d[:,0]
df['Y'] = embed_2d[:,1]
df['item'] = model.wv.index_to_key
df['pagerank'] = pagerank.values()
df['chosen'] = terms_chosen_mask

df

df.to_csv('.csv',index=False)
################################################################################################################################
from sklearn.manifold import TSNE
tsne = TSNE(n_components=3, n_iter=1000)
embed_3d = tsne.fit_transform(X)

df = pd.DataFrame()
df['X'] = embed_3d[:,0]
df['Y'] = embed_3d[:,1]
df['Z'] = embed_3d[:,2]
df['item'] = model.wv.index_to_key
df['pagerank'] = pagerank.values()
df['chosen'] = terms_chosen_mask

df

df.to_csv('.csv',index=False)
################################################################################################################################
