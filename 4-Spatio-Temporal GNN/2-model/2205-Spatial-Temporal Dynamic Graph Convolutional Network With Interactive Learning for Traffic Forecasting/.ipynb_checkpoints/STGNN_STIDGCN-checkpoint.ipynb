{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd55038-43bc-4612-b2fe-36a2df8bf94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "\n",
    "\n",
    "################################################################\n",
    "# https://github.com/LiuAoyu1998/STIDGCN\n",
    "\n",
    "# .log文件有模型结构\n",
    "################################################################\n",
    "# conda create -n STGNN_STIDGCN\n",
    "# conda activate STGNN_STIDGCN\n",
    "\n",
    "# conda install python=3.8\n",
    "\n",
    "# https://pytorch.org/get-started/previous-versions/\n",
    "# conda install pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda=11.7 -c pytorch -c nvidia\n",
    "\n",
    "\n",
    "################################################################\n",
    "# pip install pandas\n",
    "# pip install scipy\n",
    "\n",
    "\n",
    "################################################################\n",
    "# conda install ipykernel\n",
    "# conda install platformdirs\n",
    "# pip3 install ipywidgets\n",
    "# pip3 install --upgrade jupyter_core jupyter_client\n",
    "\n",
    "# python -m ipykernel install --user --name STGNN_STIDGCN\n",
    "\n",
    "\n",
    "################################################################\n",
    "# train.py    cuda:0\n",
    "\n",
    "\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b9ec6b-05f9-419d-8d96-8d7b344ebaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd  # 数据分析\n",
    "import random\n",
    "import time\n",
    "\n",
    "import util\n",
    "from util import *\n",
    "from model import STIDGCN\n",
    "from ranger21 import Ranger  # 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32efac-984b-4250-96dc-2861c95b8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--device\", type=str, default=\"cuda:0\", help=\"\")\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"PEMS08\", help=\"data path\")\n",
    "parser.add_argument(\"--input_dim\", type=int, default=3, help=\"number of input_dim\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"batch size\")\n",
    "parser.add_argument(\"--learning_rate\", type=float, default=0.001, help=\"learning rate\")\n",
    "parser.add_argument(\"--dropout\", type=float, default=0.1, help=\"dropout rate\")\n",
    "parser.add_argument(\"--weight_decay\", type=float, default=0.0001, help=\"weight decay rate\")\n",
    "parser.add_argument(\"--epochs\", type=int, default=500, help=\"\")\n",
    "parser.add_argument(\"--print_every\", type=int, default=50, help=\"\")\n",
    "parser.add_argument(\n",
    "    \"--save\", \n",
    "    type=str, \n",
    "    default=\"./logs/\" + str(time.strftime(\"%Y-%m-%d-%H:%M:%S\")) + \"-\", \n",
    "    help=\"save path\", \n",
    ")\n",
    "parser.add_argument(\"--expid\", type=int, default=1, help=\"experiment id\")\n",
    "parser.add_argument(\n",
    "    \"--es_patience\", \n",
    "    type=int, \n",
    "    default=100, \n",
    "    help=\"quit if no improvement after this many iterations\", \n",
    ")\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d680393-2fd2-464f-95fc-8c012872ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() :\n",
    "\n",
    "    seed_it(6666)\n",
    "\n",
    "    if args.dataset == \"PEMS08\" :  # [N, D, T] = 170*96*288\n",
    "        args.data_dir = \"data//\" + args.dataset\n",
    "        num_nodes = 170\n",
    "        channels = 96\n",
    "        granularity = 288\n",
    "\n",
    "    elif args.dataset == \"PEMS03\" :\n",
    "        args.data_dir = \"data//\" + args.dataset\n",
    "        num_nodes = 358\n",
    "        args.epochs = 300\n",
    "        args.es_patience = 100\n",
    "        granularity = 288\n",
    "        channels = 32\n",
    "\n",
    "    elif args.dataset == \"PEMS04\" :\n",
    "        args.data_dir = \"data//\" + args.dataset\n",
    "        num_nodes = 307\n",
    "        granularity = 288\n",
    "        channels = 64\n",
    "\n",
    "    elif args.dataset == \"PEMS07\" :\n",
    "        args.data_dir = \"data//\" + args.dataset\n",
    "        num_nodes = 883\n",
    "        granularity = 288\n",
    "        channels = 128\n",
    "\n",
    "    elif args.dataset == \"bike_drop\" :\n",
    "        args.data_dir = \"data//\" + args.dataset\n",
    "        num_nodes = 250\n",
    "        granularity = 48\n",
    "        channels = 32\n",
    "\n",
    "    elif args.dataset == \"bike_pick\" :\n",
    "        args.data_dir = \"data//\" + args.dataset\n",
    "        num_nodes = 250\n",
    "        granularity = 48\n",
    "        channels = 32\n",
    "\n",
    "    elif args.dataset == \"taxi_drop\" :\n",
    "        args.data_dir = \"data//\" + args.dataset\n",
    "        num_nodes = 266\n",
    "        granularity = 48\n",
    "        channels = 96\n",
    "\n",
    "    elif args.dataset == \"taxi_pick\" :\n",
    "        args.data_dir = \"data//\" + args.dataset\n",
    "        num_nodes = 266\n",
    "        granularity = 48\n",
    "        channels = 96\n",
    "\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    dataloader = util.load_dataset(args.data_dir, args.batch_size, args.batch_size, args.batch_size)  # 三个size一致？\n",
    "    scaler = dataloader[\"scaler\"]\n",
    "\n",
    "    loss     = 9999999\n",
    "    test_log = 999999\n",
    "    epochs_since_best_mae = 0\n",
    "    path = args.save + args.data_dir + \"/\"\n",
    "\n",
    "    his_loss = []\n",
    "    val_time = []\n",
    "    train_time = []\n",
    "    result = []\n",
    "    test_result = []\n",
    "\n",
    "    print(args)\n",
    "\n",
    "    if not os.path.exists(path) :\n",
    "        os.makedirs(path)\n",
    "\n",
    "    engine = trainer(\n",
    "        scaler, \n",
    "        args.input_dim, \n",
    "        num_nodes, \n",
    "        channels, \n",
    "        args.dropout, \n",
    "        args.learning_rate, \n",
    "        args.weight_decay, \n",
    "        device, \n",
    "        granularity, \n",
    "    )\n",
    "\n",
    "    print(\"start training...\", flush=True)\n",
    "\n",
    "    for i in range(1, args.epochs + 1) :\n",
    "        train_loss  = []\n",
    "        train_mape  = []\n",
    "        train_rmse  = []\n",
    "        train_wmape = []\n",
    "\n",
    "        t1 = time.time()\n",
    "\n",
    "        # dataloader['train_loader'].shuffle()\n",
    "        for iter, (x, y) in enumerate(dataloader[\"train_loader\"].get_iterator()) :  # 返回批数据\n",
    "\n",
    "            trainx = torch.Tensor(x).to(device)\n",
    "            trainx = trainx.transpose(1, 3)\n",
    "            trainy = torch.Tensor(y).to(device)\n",
    "            trainy = trainy.transpose(1, 3)\n",
    "\n",
    "            metrics = engine.train(trainx, trainy[:, 0, :, :])\n",
    "            train_loss.append(metrics[0])\n",
    "            train_mape.append(metrics[1])\n",
    "            train_rmse.append(metrics[2])\n",
    "            train_wmape.append(metrics[3])\n",
    "\n",
    "            if iter % args.print_every == 0 :\n",
    "                log = \"Iter: {:03d}, \\\n",
    "                       Train Loss: {:.4f}, \\\n",
    "                       Train RMSE: {:.4f}, \\\n",
    "                       Train MAPE: {:.4f}, \\\n",
    "                       Train WMAPE: {:.4f}\"\n",
    "                print(\n",
    "                    log.format(\n",
    "                        iter, \n",
    "                        train_loss[-1], \n",
    "                        train_rmse[-1], \n",
    "                        train_mape[-1], \n",
    "                        train_wmape[-1], \n",
    "                    ), \n",
    "                    flush=True, \n",
    "                )\n",
    "\n",
    "        t2 = time.time()\n",
    "        log = \"Epoch: {:03d}, Training Time: {:.4f} secs\"\n",
    "        print(log.format(i, (t2 - t1)))\n",
    "        train_time.append(t2 - t1)\n",
    "\n",
    "        valid_loss  = []\n",
    "        valid_mape  = []\n",
    "        valid_wmape = []\n",
    "        valid_rmse  = []\n",
    "\n",
    "        # \n",
    "        s1 = time.time()\n",
    "\n",
    "        for iter, (x, y) in enumerate(dataloader[\"val_loader\"].get_iterator()) :\n",
    "\n",
    "            testx = torch.Tensor(x).to(device)\n",
    "            testx = testx.transpose(1, 3)\n",
    "            testy = torch.Tensor(y).to(device)\n",
    "            testy = testy.transpose(1, 3)\n",
    "\n",
    "            metrics = engine.eval(testx, testy[:, 0, :, :])\n",
    "            valid_loss .append(metrics[0])\n",
    "            valid_mape .append(metrics[1])\n",
    "            valid_rmse .append(metrics[2])\n",
    "            valid_wmape.append(metrics[3])\n",
    "\n",
    "        s2 = time.time()\n",
    "\n",
    "        log = \"Epoch: {:03d}, Inference Time: {:.4f} secs\"\n",
    "        print(log.format(i, (s2 - s1)))\n",
    "        val_time.append(s2 - s1)\n",
    "\n",
    "        mtrain_loss  = np.mean(train_loss)\n",
    "        mtrain_mape  = np.mean(train_mape)\n",
    "        mtrain_wmape = np.mean(train_wmape)\n",
    "        mtrain_rmse  = np.mean(train_rmse)\n",
    "\n",
    "        mvalid_loss  = np.mean(valid_loss)\n",
    "        mvalid_mape  = np.mean(valid_mape)\n",
    "        mvalid_wmape = np.mean(valid_wmape)\n",
    "        mvalid_rmse  = np.mean(valid_rmse)\n",
    "\n",
    "        his_loss.append(mvalid_loss)\n",
    "        train_m = dict(\n",
    "            train_loss =np.mean(train_loss), \n",
    "            train_rmse =np.mean(train_rmse), \n",
    "            train_mape =np.mean(train_mape), \n",
    "            train_wmape=np.mean(train_wmape), \n",
    "\n",
    "            valid_loss =np.mean(valid_loss), \n",
    "            valid_rmse =np.mean(valid_rmse), \n",
    "            valid_mape =np.mean(valid_mape), \n",
    "            valid_wmape=np.mean(valid_wmape), \n",
    "        )\n",
    "        train_m = pd.Series(train_m)\n",
    "        result.append(train_m)\n",
    "\n",
    "        log = \"Epoch: {:03d}, \\\n",
    "               Train Loss: {:.4f}, \\\n",
    "               Train RMSE: {:.4f}, \\\n",
    "               Train MAPE: {:.4f}, \\\n",
    "               Train WMAPE: {:.4f}, \"\n",
    "        print(\n",
    "            log.format(i, mtrain_loss, mtrain_rmse, mtrain_mape, mtrain_wmape), \n",
    "            flush=True, \n",
    "        )\n",
    "        log = \"Epoch: {:03d}, \\\n",
    "               Valid Loss: {:.4f}, \\\n",
    "               Valid RMSE: {:.4f}, \\\n",
    "               Valid MAPE: {:.4f}, \\\n",
    "               Valid WMAPE: {:.4f}\"\n",
    "        print(\n",
    "            log.format(i, mvalid_loss, mvalid_rmse, mvalid_mape, mvalid_wmape), \n",
    "            flush=True, \n",
    "        )\n",
    "\n",
    "        if mvalid_loss < loss :\n",
    "            print(\"### Update tasks appear ###\")\n",
    "\n",
    "            if i < 100 :\n",
    "                # It is not necessary to print the results of the test set \n",
    "                # when epoch is less than 100, because the model has not yet converged.\n",
    "                loss = mvalid_loss\n",
    "                torch.save(engine.model.state_dict(), path + \"best_model.pth\")\n",
    "                bestid = i\n",
    "                epochs_since_best_mae = 0\n",
    "                print(\"Updating! Valid Loss:\", mvalid_loss, end=\", \")\n",
    "                print(\"epoch: \", i)\n",
    "\n",
    "            elif i > 100 :\n",
    "                outputs = []\n",
    "                realy = torch.Tensor(dataloader[\"y_test\"]).to(device)\n",
    "                realy = realy.transpose(1, 3)[:, 0, :, :]\n",
    "\n",
    "                for iter, (x, y) in enumerate(dataloader[\"test_loader\"].get_iterator()) :\n",
    "                    testx = torch.Tensor(x).to(device)\n",
    "                    testx = testx.transpose(1, 3)\n",
    "                    with torch.no_grad() :\n",
    "                        preds = engine.model(testx).transpose(1, 3)\n",
    "                    outputs.append(preds.squeeze())\n",
    "\n",
    "                yhat = torch.cat(outputs, dim=0)\n",
    "                yhat = yhat[: realy.size(0), ...]\n",
    "\n",
    "                amae   = []\n",
    "                amape  = []\n",
    "                awmape = []\n",
    "                armse  = []\n",
    "                test_m = []\n",
    "\n",
    "                for j in range(12) :\n",
    "\n",
    "                    pred = scaler.inverse_transform(yhat[:, :, j])\n",
    "                    real = realy[:, :, j]\n",
    "                    metrics = util.metric(pred, real)\n",
    "                    log = \"Evaluate best model on test data for horizon {:d}, \\\n",
    "                        Test MAE  : {:.4f}, \\\n",
    "                        Test RMSE : {:.4f}, \\\n",
    "                        Test MAPE : {:.4f}, \\\n",
    "                        Test WMAPE: {:.4f}\"\n",
    "                    print(\n",
    "                        log.format(\n",
    "                            j + 1, metrics[0], metrics[2], metrics[1], metrics[3]\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    test_m = dict(\n",
    "                        test_loss =np.mean(metrics[0]), \n",
    "                        test_rmse =np.mean(metrics[2]), \n",
    "                        test_mape =np.mean(metrics[1]), \n",
    "                        test_wmape=np.mean(metrics[3]), \n",
    "                    )\n",
    "                    test_m = pd.Series(test_m)\n",
    "\n",
    "                    amae  .append(metrics[0])\n",
    "                    amape .append(metrics[1])\n",
    "                    armse .append(metrics[2])\n",
    "                    awmape.append(metrics[3])\n",
    "\n",
    "                log = \"On average over 12 horizons, \\\n",
    "                       Test MAE  : {:.4f}, \\\n",
    "                       Test RMSE : {:.4f}, \\\n",
    "                       Test MAPE : {:.4f}, \\\n",
    "                       Test WMAPE: {:.4f}\"\n",
    "                print(\n",
    "                    log.format(\n",
    "                        np.mean(amae), np.mean(armse), np.mean(amape), np.mean(awmape)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if np.mean(amae) < test_log :\n",
    "                    test_log = np.mean(amae)\n",
    "                    loss = mvalid_loss\n",
    "                    torch.save(engine.model.state_dict(), path + \"best_model.pth\")\n",
    "                    epochs_since_best_mae = 0\n",
    "                    print(\"Test low! Updating! Test Loss :\", np.mean(amae), end=\", \")\n",
    "                    print(\"Test low! Updating! Valid Loss:\", mvalid_loss  , end=\", \")\n",
    "                    bestid = i\n",
    "                    print(\"epoch: \", i)\n",
    "                else :\n",
    "                    epochs_since_best_mae += 1\n",
    "                    print(\"No update\")\n",
    "\n",
    "        else :\n",
    "            epochs_since_best_mae += 1\n",
    "            print(\"No update\")\n",
    "\n",
    "        train_csv = pd.DataFrame(result)\n",
    "        train_csv.round(8).to_csv(f\"{path}/train.csv\")\n",
    "        if epochs_since_best_mae >= args.es_patience and i >= 300 :\n",
    "            break\n",
    "\n",
    "    print(\"Average Training Time : {:.4f} secs/epoch\".format(np.mean(train_time)))\n",
    "    print(\"Average Inference Time: {:.4f} secs\".format(np.mean(val_time)))\n",
    "\n",
    "    print(\"Training ends\")\n",
    "    print(\"The epoch of the best result：\", bestid)\n",
    "    print(\"The valid loss of the best model\", str(round(his_loss[bestid - 1], 4)))\n",
    "\n",
    "    engine.model.load_state_dict(torch.load(path + \"best_model.pth\"))\n",
    "    outputs = []\n",
    "    realy = torch.Tensor(dataloader[\"y_test\"]).to(device)\n",
    "    realy = realy.transpose(1, 3)[:, 0, :, :]\n",
    "\n",
    "    for iter, (x, y) in enumerate(dataloader[\"test_loader\"].get_iterator()) :\n",
    "        testx = torch.Tensor(x).to(device)\n",
    "        testx = testx.transpose(1, 3)\n",
    "        with torch.no_grad() :\n",
    "            preds = engine.model(testx).transpose(1, 3)\n",
    "        outputs.append(preds.squeeze())\n",
    "\n",
    "    yhat = torch.cat(outputs, dim=0)\n",
    "    yhat = yhat[: realy.size(0), ...]\n",
    "\n",
    "    amae   = []\n",
    "    amape  = []\n",
    "    armse  = []\n",
    "    awmape = []\n",
    "\n",
    "    test_m = []\n",
    "\n",
    "    for i in range(12) :\n",
    "        pred = scaler.inverse_transform(yhat[:, :, i])\n",
    "        real = realy[:, :, i]\n",
    "        metrics = util.metric(pred, real)\n",
    "        log = \"Evaluate best model on test data for horizon {:d}, \\\n",
    "               Test MAE: {:.4f}, \\\n",
    "               Test RMSE: {:.4f}, \\\n",
    "               Test MAPE: {:.4f}, \\\n",
    "               Test WMAPE: {:.4f}\"\n",
    "        print(log.format(i + 1, metrics[0], metrics[2], metrics[1], metrics[3]))\n",
    "\n",
    "        test_m = dict(\n",
    "            test_loss =np.mean(metrics[0]), \n",
    "            test_rmse =np.mean(metrics[2]), \n",
    "            test_mape =np.mean(metrics[1]), \n",
    "            test_wmape=np.mean(metrics[3]), \n",
    "        )\n",
    "        test_m = pd.Series(test_m)\n",
    "        test_result.append(test_m)\n",
    "\n",
    "        amae  .append(metrics[0])\n",
    "        amape .append(metrics[1])\n",
    "        armse .append(metrics[2])\n",
    "        awmape.append(metrics[3])\n",
    "\n",
    "    log = \"On average over 12 horizons, \\\n",
    "           Test MAE: {:.4f}, \\\n",
    "           Test RMSE: {:.4f}, \\\n",
    "           Test MAPE: {:.4f}, \\\n",
    "           Test WMAPE: {:.4f}\"\n",
    "    print(log.format(np.mean(amae), np.mean(armse), np.mean(amape), np.mean(awmape)))\n",
    "\n",
    "    test_m = dict(\n",
    "        test_loss =np.mean(amae), \n",
    "        test_rmse =np.mean(armse), \n",
    "        test_mape =np.mean(amape), \n",
    "        test_wmape=np.mean(awmape), \n",
    "    )\n",
    "    test_m = pd.Series(test_m)\n",
    "    test_result.append(test_m)\n",
    "\n",
    "    test_csv = pd.DataFrame(test_result)\n",
    "    test_csv.round(8).to_csv(f\"{path}/test.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba8c87b-da6e-4350-932c-52ab8fe258e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "\n",
    "    t1 = time.time()\n",
    "    main()\n",
    "    t2 = time.time()\n",
    "    print(\"Total time spent: {:.4f}\".format(t2 - t1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STGNN_STIDGCN",
   "language": "python",
   "name": "stgnn_stidgcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
