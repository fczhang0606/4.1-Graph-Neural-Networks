Perform shuffle on the dataset
Namespace(batch_size=64, data='data//bike_drop', device='cuda:0', dropout=0.1, epochs=500, es_patience=100, expid=1, input_dim=3, learning_rate=0.001, print_every=50, save='./logs/2024-08-05-11:23:28-', weight_decay=0.0001)
Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
The number of parameters: 683317
STIDGCN(
  (Temb): TemporalEmbedding()
  (start_conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
  (tree): IDGCN_Tree(
    (IDGCN1): IDGCN(
      (split): Splitting()
      (conv1): Sequential(
        (0): ReplicationPad2d((3, 3, 0, 0))
        (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1))
        (2): LeakyReLU(negative_slope=0.01, inplace=True)
        (3): Dropout(p=0.1, inplace=False)
        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
        (5): Tanh()
      )
      (conv2): Sequential(
        (0): ReplicationPad2d((3, 3, 0, 0))
        (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1))
        (2): LeakyReLU(negative_slope=0.01, inplace=True)
        (3): Dropout(p=0.1, inplace=False)
        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
        (5): Tanh()
      )
      (conv3): Sequential(
        (0): ReplicationPad2d((3, 3, 0, 0))
        (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1))
        (2): LeakyReLU(negative_slope=0.01, inplace=True)
        (3): Dropout(p=0.1, inplace=False)
        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
        (5): Tanh()
      )
      (conv4): Sequential(
        (0): ReplicationPad2d((3, 3, 0, 0))
        (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1))
        (2): LeakyReLU(negative_slope=0.01, inplace=True)
        (3): Dropout(p=0.1, inplace=False)
        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
        (5): Tanh()
      )
      (dgcn): DGCN(
        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        (generator): Graph_Generator(
          (fc): Linear(in_features=2, out_features=1, bias=True)
        )
        (gcn): Diffusion_GCN(
          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (IDGCN2): IDGCN(
      (split): Splitting()
      (conv1): Sequential(
        (0): ReplicationPad2d((3, 3, 0, 0))
        (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1))
        (2): LeakyReLU(negative_slope=0.01, inplace=True)
        (3): Dropout(p=0.1, inplace=False)
        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
        (5): Tanh()
      )
      (conv2): Sequential(
        (0): ReplicationPad2d((3, 3, 0, 0))
        (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1))
        (2): LeakyReLU(negative_slope=0.01, inplace=True)
        (3): Dropout(p=0.1, inplace=False)
        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
        (5): Tanh()
      )
      (conv3): Sequential(
        (0): ReplicationPad2d((3, 3, 0, 0))
        (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1))
        (2): LeakyReLU(negative_slope=0.01, inplace=True)
        (3): Dropout(p=0.1, inplace=False)
        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
        (5): Tanh()
      )
      (conv4): Sequential(
        (0): ReplicationPad2d((3, 3, 0, 0))
        (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1))
        (2): LeakyReLU(negative_slope=0.01, inplace=True)
        (3): Dropout(p=0.1, inplace=False)
        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
        (5): Tanh()
      )
      (dgcn): DGCN(
        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        (generator): Graph_Generator(
          (fc): Linear(in_features=2, out_features=1, bias=True)
        )
        (gcn): Diffusion_GCN(
          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (IDGCN3): IDGCN(
      (split): Splitting()
      (conv1): Sequential(
        (0): ReplicationPad2d((3, 3, 0, 0))
        (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1))
        (2): LeakyReLU(negative_slope=0.01, inplace=True)
        (3): Dropout(p=0.1, inplace=False)
        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
        (5): Tanh()
      )
      (conv2): Sequential(
        (0): ReplicationPad2d((3, 3, 0, 0))
        (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1))
        (2): LeakyReLU(negative_slope=0.01, inplace=True)
        (3): Dropout(p=0.1, inplace=False)
        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
        (5): Tanh()
      )
      (conv3): Sequential(
        (0): ReplicationPad2d((3, 3, 0, 0))
        (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1))
        (2): LeakyReLU(negative_slope=0.01, inplace=True)
        (3): Dropout(p=0.1, inplace=False)
        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
        (5): Tanh()
      )
      (conv4): Sequential(
        (0): ReplicationPad2d((3, 3, 0, 0))
        (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1))
        (2): LeakyReLU(negative_slope=0.01, inplace=True)
        (3): Dropout(p=0.1, inplace=False)
        (4): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
        (5): Tanh()
      )
      (dgcn): DGCN(
        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        (generator): Graph_Generator(
          (fc): Linear(in_features=2, out_features=1, bias=True)
        )
        (gcn): Diffusion_GCN(
          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (glu): GLU(
    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
    (conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
    (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (regression_layer): Conv2d(64, 12, kernel_size=(1, 12), stride=(1, 1))
)
start training...
Iter: 000, Train Loss: 2.8127, Train RMSE: 4.5107, Train MAPE: 0.7430, Train WMAPE: 0.6743
Epoch: 001, Training Time: 4.6128 secs
Epoch: 001, Inference Time: 0.3666 secs
Epoch: 001, Train Loss: 2.5969, Train RMSE: 4.2195, Train MAPE: 0.7482, Train WMAPE: 0.6486, 
Epoch: 001, Valid Loss: 2.8908, Valid RMSE: 4.7035, Valid MAPE: 0.7122, Valid WMAPE: 0.6332
###Update tasks appear###
Updating! Valid Loss: 2.8908437490463257, epoch:  1
Iter: 000, Train Loss: 2.5831, Train RMSE: 4.2456, Train MAPE: 0.7271, Train WMAPE: 0.6192
Epoch: 002, Training Time: 4.1014 secs
Epoch: 002, Inference Time: 0.3704 secs
Epoch: 002, Train Loss: 2.4701, Train RMSE: 4.0271, Train MAPE: 0.7659, Train WMAPE: 0.6171, 
Epoch: 002, Valid Loss: 2.8108, Valid RMSE: 4.5833, Valid MAPE: 0.7156, Valid WMAPE: 0.6157
###Update tasks appear###
Updating! Valid Loss: 2.8108261823654175, epoch:  2
Iter: 000, Train Loss: 2.5253, Train RMSE: 4.1498, Train MAPE: 0.7344, Train WMAPE: 0.6054
Epoch: 003, Training Time: 4.1138 secs
Epoch: 003, Inference Time: 0.3669 secs
Epoch: 003, Train Loss: 2.4157, Train RMSE: 3.9583, Train MAPE: 0.7486, Train WMAPE: 0.6035, 
Epoch: 003, Valid Loss: 2.7459, Valid RMSE: 4.5056, Valid MAPE: 0.6904, Valid WMAPE: 0.6015
###Update tasks appear###
Updating! Valid Loss: 2.7458955390112743, epoch:  3
Iter: 000, Train Loss: 2.4702, Train RMSE: 4.0947, Train MAPE: 0.7022, Train WMAPE: 0.5922
Epoch: 004, Training Time: 4.1155 secs
Epoch: 004, Inference Time: 0.3638 secs
Epoch: 004, Train Loss: 2.3533, Train RMSE: 3.8749, Train MAPE: 0.7237, Train WMAPE: 0.5879, 
Epoch: 004, Valid Loss: 2.6463, Valid RMSE: 4.3521, Valid MAPE: 0.6754, Valid WMAPE: 0.5797
###Update tasks appear###
Updating! Valid Loss: 2.6463019166673933, epoch:  4
Iter: 000, Train Loss: 2.3934, Train RMSE: 3.9667, Train MAPE: 0.6962, Train WMAPE: 0.5738
Epoch: 005, Training Time: 4.1027 secs
Epoch: 005, Inference Time: 0.3646 secs
Epoch: 005, Train Loss: 2.2733, Train RMSE: 3.7509, Train MAPE: 0.7020, Train WMAPE: 0.5679, 
Epoch: 005, Valid Loss: 2.5392, Valid RMSE: 4.1966, Valid MAPE: 0.6466, Valid WMAPE: 0.5563
###Update tasks appear###
Updating! Valid Loss: 2.5392357281276157, epoch:  5
Iter: 000, Train Loss: 2.3222, Train RMSE: 3.8534, Train MAPE: 0.6805, Train WMAPE: 0.5567
Epoch: 006, Training Time: 4.0741 secs
Epoch: 006, Inference Time: 0.3651 secs
Epoch: 006, Train Loss: 2.1888, Train RMSE: 3.6082, Train MAPE: 0.6870, Train WMAPE: 0.5468, 
Epoch: 006, Valid Loss: 2.4678, Valid RMSE: 4.0997, Valid MAPE: 0.6036, Valid WMAPE: 0.5406
###Update tasks appear###
Updating! Valid Loss: 2.467767664364406, epoch:  6
Iter: 000, Train Loss: 2.2528, Train RMSE: 3.7753, Train MAPE: 0.6277, Train WMAPE: 0.5401
Epoch: 007, Training Time: 4.1047 secs
Epoch: 007, Inference Time: 0.3649 secs
Epoch: 007, Train Loss: 2.1245, Train RMSE: 3.4935, Train MAPE: 0.6770, Train WMAPE: 0.5307, 
Epoch: 007, Valid Loss: 2.4018, Valid RMSE: 3.9866, Valid MAPE: 0.5903, Valid WMAPE: 0.5263
###Update tasks appear###
Updating! Valid Loss: 2.401791947228568, epoch:  7
Iter: 000, Train Loss: 2.1891, Train RMSE: 3.6623, Train MAPE: 0.6193, Train WMAPE: 0.5248
Epoch: 008, Training Time: 4.1050 secs
Epoch: 008, Inference Time: 0.3645 secs
Epoch: 008, Train Loss: 2.0743, Train RMSE: 3.4008, Train MAPE: 0.6684, Train WMAPE: 0.5182, 
Epoch: 008, Valid Loss: 2.3617, Valid RMSE: 3.9189, Valid MAPE: 0.5755, Valid WMAPE: 0.5175
###Update tasks appear###
Updating! Valid Loss: 2.361679741314479, epoch:  8
Iter: 000, Train Loss: 2.1505, Train RMSE: 3.5987, Train MAPE: 0.6067, Train WMAPE: 0.5156
Epoch: 009, Training Time: 4.0969 secs
Epoch: 009, Inference Time: 0.3647 secs
Epoch: 009, Train Loss: 2.0355, Train RMSE: 3.3283, Train MAPE: 0.6570, Train WMAPE: 0.5085, 
Epoch: 009, Valid Loss: 2.3099, Valid RMSE: 3.8252, Valid MAPE: 0.5683, Valid WMAPE: 0.5062
###Update tasks appear###
Updating! Valid Loss: 2.309937136513846, epoch:  9
Iter: 000, Train Loss: 2.1051, Train RMSE: 3.5151, Train MAPE: 0.6014, Train WMAPE: 0.5047
Epoch: 010, Training Time: 4.1023 secs
Epoch: 010, Inference Time: 0.3736 secs
Epoch: 010, Train Loss: 1.9985, Train RMSE: 3.2568, Train MAPE: 0.6474, Train WMAPE: 0.4993, 
Epoch: 010, Valid Loss: 2.2729, Valid RMSE: 3.7530, Valid MAPE: 0.5599, Valid WMAPE: 0.4981
###Update tasks appear###
Updating! Valid Loss: 2.272918939590454, epoch:  10
Iter: 000, Train Loss: 2.0714, Train RMSE: 3.4489, Train MAPE: 0.5935, Train WMAPE: 0.4966
