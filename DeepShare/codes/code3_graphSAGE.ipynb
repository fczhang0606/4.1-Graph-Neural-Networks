{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhang\\miniconda3\\envs\\pyg\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Pubmed()\n",
      "-------------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 19717\n",
      "Number of features: 500\n",
      "Number of classes: 3\n",
      "\n",
      "Graph:\n",
      "------\n",
      "Training nodes: 60\n",
      "Evaluation nodes: 500\n",
      "Test nodes: 1000\n",
      "Edges are directed: False\n",
      "Graph has isolated nodes: False\n",
      "Graph has loops: False\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='.', name=\"Pubmed\")\n",
    "data = dataset[0]\n",
    "\n",
    "# Print information about the dataset\n",
    "print(f'Dataset: {dataset}')\n",
    "print('-------------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# Print information about the graph\n",
    "print(f'\\nGraph:')\n",
    "print('------')\n",
    "print(f'Training nodes: {sum(data.train_mask).item()}')\n",
    "print(f'Evaluation nodes: {sum(data.val_mask).item()}')\n",
    "print(f'Test nodes: {sum(data.test_mask).item()}')\n",
    "print(f'Edges are directed: {data.is_directed()}')\n",
    "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Graph has loops: {data.has_self_loops()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "# Create batches with neighbor sampling\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[5, 10],\n",
    "    batch_size=16,\n",
    "    input_nodes=data.train_mask,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Dropout\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "  \"\"\"GraphSAGE\"\"\"\n",
    "  def __init__(self, dim_in, dim_h, dim_out):\n",
    "    super().__init__()\n",
    "    self.sage1 = SAGEConv(dim_in, dim_h)\n",
    "    self.sage2 = SAGEConv(dim_h, dim_out)\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                      lr=0.01,\n",
    "                                      weight_decay=5e-4)\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    h = self.sage1(x, edge_index).relu()\n",
    "    h = F.dropout(h, p=0.5, training=self.training)\n",
    "    h = self.sage2(h, edge_index)\n",
    "    return F.log_softmax(h, dim=1)\n",
    "\n",
    "  def fit(self, data, epochs):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = self.optimizer\n",
    "\n",
    "    self.train()\n",
    "    for epoch in range(epochs + 1):\n",
    "      total_loss = 0\n",
    "      acc = 0\n",
    "      val_loss = 0\n",
    "      val_acc = 0\n",
    "\n",
    "      # Train on batches\n",
    "      for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = self(batch.x, batch.edge_index)\n",
    "        loss = criterion(out[batch.train_mask], batch.y[batch.train_mask])\n",
    "        total_loss += loss\n",
    "        acc += accuracy(out[batch.train_mask].argmax(dim=1), \n",
    "                        batch.y[batch.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        val_loss += criterion(out[batch.val_mask], batch.y[batch.val_mask])\n",
    "        val_acc += accuracy(out[batch.val_mask].argmax(dim=1), \n",
    "                            batch.y[batch.val_mask])\n",
    "\n",
    "      # Print metrics every 10 epochs\n",
    "      if(epoch % 10 == 0):\n",
    "          print(f'Epoch {epoch:>3} | Train Loss: {total_loss/len(train_loader):.3f} '\n",
    "                f'| Train Acc: {acc/len(train_loader)*100:>6.2f}% | Val Loss: '\n",
    "                f'{val_loss/len(train_loader):.2f} | Val Acc: '\n",
    "                f'{val_acc/len(train_loader)*100:.2f}%')\n",
    "\n",
    "def accuracy(pred_y, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    \"\"\"Evaluate the model on test set and print the accuracy score.\"\"\"\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE(\n",
      "  (sage1): SAGEConv(500, 64, aggr=mean)\n",
      "  (sage2): SAGEConv(64, 3, aggr=mean)\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.127 | Train Acc:  30.24% | Val Loss: 1.12 | Val Acc: 26.08%\n",
      "Epoch  10 | Train Loss: 0.077 | Train Acc: 100.00% | Val Loss: 0.66 | Val Acc: 71.25%\n",
      "Epoch  20 | Train Loss: 0.029 | Train Acc: 100.00% | Val Loss: 0.49 | Val Acc: 77.11%\n",
      "Epoch  30 | Train Loss: 0.034 | Train Acc: 100.00% | Val Loss: 0.57 | Val Acc: 77.50%\n",
      "Epoch  40 | Train Loss: 0.023 | Train Acc: 100.00% | Val Loss: 0.62 | Val Acc: 84.68%\n",
      "Epoch  50 | Train Loss: 0.017 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 72.57%\n",
      "Epoch  60 | Train Loss: 0.015 | Train Acc: 100.00% | Val Loss: 0.48 | Val Acc: 81.25%\n",
      "Epoch  70 | Train Loss: 0.013 | Train Acc: 100.00% | Val Loss: 0.50 | Val Acc: 72.85%\n",
      "Epoch  80 | Train Loss: 0.020 | Train Acc: 100.00% | Val Loss: 0.46 | Val Acc: 77.80%\n",
      "Epoch  90 | Train Loss: 0.021 | Train Acc: 100.00% | Val Loss: 0.48 | Val Acc: 70.35%\n",
      "Epoch 100 | Train Loss: 0.020 | Train Acc: 100.00% | Val Loss: 0.54 | Val Acc: 73.33%\n",
      "Epoch 110 | Train Loss: 0.014 | Train Acc: 100.00% | Val Loss: 0.49 | Val Acc: 79.00%\n",
      "Epoch 120 | Train Loss: 0.010 | Train Acc: 100.00% | Val Loss: 0.51 | Val Acc: 77.25%\n",
      "Epoch 130 | Train Loss: 0.019 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 72.08%\n",
      "Epoch 140 | Train Loss: 0.013 | Train Acc: 100.00% | Val Loss: 0.50 | Val Acc: 83.61%\n",
      "Epoch 150 | Train Loss: 0.011 | Train Acc: 100.00% | Val Loss: 0.62 | Val Acc: 74.52%\n",
      "Epoch 160 | Train Loss: 0.025 | Train Acc: 100.00% | Val Loss: 0.50 | Val Acc: 82.12%\n",
      "Epoch 170 | Train Loss: 0.012 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 83.12%\n",
      "Epoch 180 | Train Loss: 0.013 | Train Acc: 100.00% | Val Loss: 0.49 | Val Acc: 80.26%\n",
      "Epoch 190 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.34 | Val Acc: 86.29%\n",
      "Epoch 200 | Train Loss: 0.010 | Train Acc: 100.00% | Val Loss: 0.36 | Val Acc: 84.52%\n",
      "\n",
      "GraphSAGE test accuracy: 76.20%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graphsage = GraphSAGE(dataset.num_features, 64, dataset.num_classes)\n",
    "print(graphsage)\n",
    "\n",
    "# Train\n",
    "graphsage.fit(data, 200)\n",
    "\n",
    "# Test\n",
    "print(f'\\nGraphSAGE test accuracy: {test(graphsage, data)*100:.2f}%\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e072bb87b450b56b1e5a03e14a0880e92595f31372567c51221b1480325032dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
